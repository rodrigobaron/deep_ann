{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTE ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define to get all features (id excluded) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_x(df_x):\n",
    "    return df_x[['x0','y0','x1','y1','x2','y2','x3','y3','x4','y4','x5','y5','x6','y6','x7','y7','x8','y8','x9','y9']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define to get all results (id excluded)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_y(df_y):\n",
    "    return df_y[[\"slope\", \"intercept\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train datasets, process collumns and split in train/test data 90%/10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = pd.read_csv(\"train_100k.csv\")\n",
    "x_data = preprocess_x(x_data)\n",
    "\n",
    "y_data = pd.read_csv(\"train_100k.truth.csv\")\n",
    "y_data =  preprocess_y(y_data)\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_data,\n",
    "                                                                        y_data,\n",
    "                                                                        test_size = 0.1,\n",
    "                                                                        random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test datasets and process collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_eval = pd.read_csv(\"train_100k.csv\")\n",
    "x_data_eval = preprocess_x(x_data_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ANN\n",
    "The first, I'm tring to figure out how transfor the two output in one point. So i read again the problem set and decide only to make a simple artificial neural network with two output in a linear activation function (no activation at all)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Configuration  \n",
    "Some tests:  \n",
    "Epoch: 1000 cost = 0.138191439 cost2 = 47.019507828 4x200 learning rate 0.001   \n",
    "Epoch: 1000 cost = 0.017634519 cost2 = 11.450007486 5x400 learning rate 0.001  \n",
    "Epoch: 1000 cost = 0.008747602 cost2 = 6.681912537 4x500 learning rate 0.0001  \n",
    "\n",
    "So, how more hidden reurons and smaller learning rate, more performance in the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "training_epochs = 5000\n",
    "batch_size = 1000\n",
    "display_step = 100\n",
    "\n",
    "train_data_size = 90000\n",
    "test_data_size = 10000\n",
    "data_size = train_data_size + test_data_size\n",
    "\n",
    "n_hidden = 1000 # number of neurons on hidden layer\n",
    "\n",
    "n_input = 20\n",
    "n_output = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features and response tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_output])\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors w'll be optimized:  \n",
    "5 hidden layers  \n",
    "1 output layer  \n",
    "5 hidden bias  \n",
    "1 output bias  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden],stddev=0.1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'h4': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'h5': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output],stddev=0.1))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b4': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b5': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a fully connected ANN .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(x, weights, biases, dropout_keep_prob):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.dropout(tf.nn.tanh(layer_1), dropout_keep_prob)\n",
    "\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.dropout(tf.nn.tanh(layer_2), dropout_keep_prob)\n",
    "\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.dropout(tf.nn.tanh(layer_3), dropout_keep_prob)\n",
    "    \n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.dropout(tf.nn.tanh(layer_4), dropout_keep_prob)\n",
    "    \n",
    "    layer_5 = tf.add(tf.matmul(layer_4, weights['h5']), biases['b5'])\n",
    "    layer_5 = tf.nn.tanh(layer_5)\n",
    "\n",
    "    out_layer = tf.matmul(layer_5, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run feed forward ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = make_network(x, weights, biases, dropout_keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope_cost = tf.reduce_mean(tf.square(y_pred[:,0]-y[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intercept_cost = tf.reduce_mean(tf.abs(y_pred[:,1]-y[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run backward propagation to adjust cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope_optimizer =  tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(slope_cost)\n",
    "intercept_optimizer =  tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(intercept_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create batches to train in more small steps an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 Slope MSE cost= 0.092724972 Intercept MAE cost= 20.650480058\n",
      "Epoch: 200 Slope MSE cost= 0.029275044 Intercept MAE cost= 14.340603648\n",
      "Epoch: 300 Slope MSE cost= 0.015431797 Intercept MAE cost= 11.042841201\n",
      "Epoch: 400 Slope MSE cost= 0.010297216 Intercept MAE cost= 8.920403025\n",
      "Epoch: 500 Slope MSE cost= 0.007844613 Intercept MAE cost= 7.408725855\n",
      "Epoch: 600 Slope MSE cost= 0.006090730 Intercept MAE cost= 6.450064129\n",
      "Epoch: 700 Slope MSE cost= 0.005266885 Intercept MAE cost= 5.814264758\n",
      "Epoch: 800 Slope MSE cost= 0.004933458 Intercept MAE cost= 5.276647393\n",
      "Epoch: 900 Slope MSE cost= 0.003926165 Intercept MAE cost= 4.914394490\n",
      "Epoch: 1000 Slope MSE cost= 0.003533717 Intercept MAE cost= 4.538295767\n",
      "Epoch: 1100 Slope MSE cost= 0.003262276 Intercept MAE cost= 4.662337091\n",
      "Epoch: 1200 Slope MSE cost= 0.002920492 Intercept MAE cost= 4.189010008\n",
      "Epoch: 1300 Slope MSE cost= 0.003018943 Intercept MAE cost= 4.062330151\n",
      "Epoch: 1400 Slope MSE cost= 0.002576584 Intercept MAE cost= 3.910287073\n",
      "Epoch: 1500 Slope MSE cost= 0.002464927 Intercept MAE cost= 3.876728018\n",
      "Epoch: 1600 Slope MSE cost= 0.002346456 Intercept MAE cost= 3.591257779\n",
      "Epoch: 1700 Slope MSE cost= 0.002317611 Intercept MAE cost= 3.562907094\n",
      "Epoch: 1800 Slope MSE cost= 0.002099539 Intercept MAE cost= 3.359890368\n",
      "Epoch: 1900 Slope MSE cost= 0.002594674 Intercept MAE cost= 3.463582881\n",
      "Epoch: 2000 Slope MSE cost= 0.001883711 Intercept MAE cost= 3.194773595\n",
      "Epoch: 2100 Slope MSE cost= 0.001781144 Intercept MAE cost= 3.180968457\n",
      "Epoch: 2200 Slope MSE cost= 0.001710860 Intercept MAE cost= 3.212306560\n",
      "Epoch: 2300 Slope MSE cost= 0.001819567 Intercept MAE cost= 2.965567933\n",
      "Epoch: 2400 Slope MSE cost= 0.001623871 Intercept MAE cost= 2.910657366\n",
      "Epoch: 2500 Slope MSE cost= 0.001589132 Intercept MAE cost= 2.878702392\n",
      "Epoch: 2600 Slope MSE cost= 0.001850457 Intercept MAE cost= 3.194309558\n",
      "Epoch: 2700 Slope MSE cost= 0.001531308 Intercept MAE cost= 2.860093029\n",
      "Epoch: 2800 Slope MSE cost= 0.001470482 Intercept MAE cost= 2.678144434\n",
      "Epoch: 2900 Slope MSE cost= 0.001621938 Intercept MAE cost= 2.982417697\n",
      "Epoch: 3000 Slope MSE cost= 0.001404625 Intercept MAE cost= 2.642429442\n",
      "Epoch: 3100 Slope MSE cost= 0.001437342 Intercept MAE cost= 2.785618827\n",
      "Epoch: 3200 Slope MSE cost= 0.002275646 Intercept MAE cost= 2.712107624\n",
      "Epoch: 3300 Slope MSE cost= 0.001327075 Intercept MAE cost= 2.634963939\n",
      "Epoch: 3400 Slope MSE cost= 0.001324765 Intercept MAE cost= 2.437745301\n",
      "Epoch: 3500 Slope MSE cost= 0.001363214 Intercept MAE cost= 2.423542221\n",
      "Epoch: 3600 Slope MSE cost= 0.001318460 Intercept MAE cost= 2.544689491\n",
      "Epoch: 3700 Slope MSE cost= 0.001985623 Intercept MAE cost= 2.420431664\n",
      "Epoch: 3800 Slope MSE cost= 0.001278420 Intercept MAE cost= 2.433984166\n",
      "Epoch: 3900 Slope MSE cost= 0.001209886 Intercept MAE cost= 2.365857079\n",
      "Epoch: 4000 Slope MSE cost= 0.001382821 Intercept MAE cost= 2.333409707\n",
      "Epoch: 4100 Slope MSE cost= 0.001195283 Intercept MAE cost= 2.268838188\n",
      "Epoch: 4200 Slope MSE cost= 0.001243663 Intercept MAE cost= 2.287148025\n",
      "Epoch: 4300 Slope MSE cost= 0.001404904 Intercept MAE cost= 2.330994868\n",
      "Epoch: 4400 Slope MSE cost= 0.001174455 Intercept MAE cost= 2.197844370\n",
      "Epoch: 4500 Slope MSE cost= 0.001158166 Intercept MAE cost= 2.184892731\n",
      "Epoch: 4600 Slope MSE cost= 0.001165453 Intercept MAE cost= 2.215855520\n",
      "Epoch: 4700 Slope MSE cost= 0.001819302 Intercept MAE cost= 2.204838555\n",
      "Epoch: 4800 Slope MSE cost= 0.001121996 Intercept MAE cost= 2.126788521\n",
      "Epoch: 4900 Slope MSE cost= 0.001133300 Intercept MAE cost= 2.091050427\n",
      "Epoch: 5000 Slope MSE cost= 0.001185747 Intercept MAE cost= 2.114788911\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_batch = int(train_data_size / batch_size)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        avg_cost2 = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = x_data_train[i * batch_size:min(i * batch_size + batch_size, train_data_size), :], \\\n",
    "                             y_data_train[i * batch_size:min(i * batch_size + batch_size, train_data_size), :]\n",
    "            # Train batch\n",
    "            sess.run([slope_optimizer,  intercept_optimizer], feed_dict={x: batch_x, y: batch_y, dropout_keep_prob: 0.9})\n",
    "            # Calculate cost\n",
    "            slope_c, intercept_c = sess.run([slope_cost, intercept_cost], feed_dict={x: batch_x, y: batch_y, dropout_keep_prob: 1.})\n",
    "            # Calculate avg cost\n",
    "            avg_cost += slope_c / total_batch\n",
    "            avg_cost2 += intercept_c / total_batch\n",
    "        \n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print('Epoch:', (epoch + 1), 'Slope MSE cost=', '{:.9f}'.format(avg_cost), 'Intercept MAE cost=', '{:.9f}'.format(avg_cost2))\n",
    "    \n",
    "    # Generate train result \n",
    "    r = sess.run(y_pred, feed_dict = {x: x_data, dropout_keep_prob: 1.})\n",
    "    r = pd.DataFrame(r, columns=[\"slope\", \"intercept\"])\n",
    "    r.to_csv(\"submission.train_100k.csv\", index=True, index_label='id')\n",
    "    \n",
    "    # Generate test result\n",
    "    r = sess.run(y_pred, feed_dict = {x: x_data_eval, dropout_keep_prob: 1.})\n",
    "    r = pd.DataFrame(r, columns=[\"slope\", \"intercept\"])\n",
    "    r.to_csv(\"submission.test_100k.csv\", index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python evaluate.py train_100k.truth.csv submission.train_100k.csv  \n",
    "Slope mse: 0.00446848524925  \n",
    "Intercept mae: 3.44408998703  \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
