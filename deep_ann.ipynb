{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTE ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define to get all features (id excluded) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_x(df_x):\n",
    "    return df_x[['x0','y0','x1','y1','x2','y2','x3','y3','x4','y4','x5','y5','x6','y6','x7','y7','x8','y8','x9','y9']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define to get all results (id excluded)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_y(df_y):\n",
    "    return df_y[[\"slope\", \"intercept\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train datasets, process collumns and split in train/test data 90%/10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv(\"train_100k.csv\")\n",
    "x_data = preprocess_x(x_data)\n",
    "\n",
    "y_data = pd.read_csv(\"train_100k.truth.csv\")\n",
    "y_data =  preprocess_y(y_data)\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_data,\n",
    "                                                                        y_data,\n",
    "                                                                        test_size = 0.1,\n",
    "                                                                        random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test datasets and process collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_eval = pd.read_csv(\"train_100k.csv\")\n",
    "x_data_eval = preprocess_x(x_data_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ANN\n",
    "The first, I'm tring to figure out how transfor the two output in one point. So i read again the problem set and decide only to make a simple artificial neural network with two output in a linear activation function (no activation at all)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Configuration  \n",
    "Some tests:  \n",
    "Epoch: 1000 cost = 0.138191439 cost2 = 47.019507828 4x200 learning rate 0.001   \n",
    "Epoch: 1000 cost = 0.017634519 cost2 = 11.450007486 5x400 learning rate 0.001  \n",
    "Epoch: 1000 cost = 0.008747602 cost2 = 6.681912537 4x500 learning rate 0.0001  \n",
    "\n",
    "So, how more hidden reurons and smaller learning rate, more performance in the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "training_epochs = 5000\n",
    "batch_size = 1000\n",
    "display_step = 100\n",
    "\n",
    "train_data_size = 90000\n",
    "test_data_size = 10000\n",
    "data_size = train_data_size + test_data_size\n",
    "\n",
    "n_hidden = 1000 # number of neurons on hidden layer\n",
    "\n",
    "n_input = 20\n",
    "n_output = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features and response tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_output])\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors w'll be optimized:  \n",
    "5 hidden layers  \n",
    "1 output layer  \n",
    "5 hidden bias  \n",
    "1 output bias  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden],stddev=0.1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'h4': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'h5': tf.Variable(tf.random_normal([n_hidden, n_hidden],stddev=0.1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output],stddev=0.1))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b4': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b5': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a fully connected ANN .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(x, weights, biases, dropout_keep_prob):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.dropout(tf.nn.tanh(layer_1), dropout_keep_prob)\n",
    "\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.dropout(tf.nn.tanh(layer_2), dropout_keep_prob)\n",
    "\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.dropout(tf.nn.tanh(layer_3), dropout_keep_prob)\n",
    "    \n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.dropout(tf.nn.tanh(layer_4), dropout_keep_prob)\n",
    "    \n",
    "    layer_5 = tf.add(tf.matmul(layer_4, weights['h5']), biases['b5'])\n",
    "    layer_5 = tf.nn.tanh(layer_5)\n",
    "\n",
    "    out_layer = tf.matmul(layer_5, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run feed forward ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = make_network(x, weights, biases, dropout_keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope_cost = tf.reduce_mean(tf.square(y_pred[:,0]-y[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intercept_cost = tf.reduce_mean(tf.abs(y_pred[:,1]-y[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run backward propagation to adjust cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope_optimizer =  tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(slope_cost)\n",
    "intercept_optimizer =  tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(intercept_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create batches to train in more small steps an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_batch = int(train_data_size / batch_size)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        avg_cost2 = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = x_data_train[i * batch_size:min(i * batch_size + batch_size, train_data_size), :], \\\n",
    "                             y_data_train[i * batch_size:min(i * batch_size + batch_size, train_data_size), :]\n",
    "            # Train batch\n",
    "            sess.run([slope_optimizer,  intercept_optimizer], feed_dict={x: batch_x, y: batch_y, dropout_keep_prob: 0.9})\n",
    "            # Calculate cost\n",
    "            slope_c, intercept_c = sess.run([slope_cost, intercept_cost], feed_dict={x: batch_x, y: batch_y, dropout_keep_prob: 1.})\n",
    "            # Calculate avg cost\n",
    "            avg_cost += slope_c / total_batch\n",
    "            avg_cost2 += intercept_c / total_batch\n",
    "        \n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print('Epoch:', (epoch + 1), 'Slope MSE cost=', '{:.9f}'.format(avg_cost), 'Intercept MAE cost=', '{:.9f}'.format(avg_cost2))\n",
    "    \n",
    "    # Generate train result \n",
    "    r = sess.run(y_pred, feed_dict = {x: x_data, dropout_keep_prob: 1.})\n",
    "    r = pd.DataFrame(r, columns=[\"slope\", \"intercept\"])\n",
    "    r.to_csv(\"submission.train_100k.csv\", index=True, index_label='id')\n",
    "    \n",
    "    # Generate test result\n",
    "    r = sess.run(y_pred, feed_dict = {x: x_data_eval, dropout_keep_prob: 1.})\n",
    "    r = pd.DataFrame(r, columns=[\"slope\", \"intercept\"])\n",
    "    r.to_csv(\"submission.test_100k.csv\", index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python evaluate.py train_100k.truth.csv submission.train_100k.csv  \n",
    "Slope mse: 0.0114102844069  \n",
    "Intercept mae: 2.29707436696  \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
